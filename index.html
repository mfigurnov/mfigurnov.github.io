<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KKWC6RB5WS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-KKWC6RB5WS');
  </script>

  <title>Michael Figurnov</title>
  
  <meta name="author" content="Michael Figurnov">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/michael-figurnov-small.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/michael-figurnov.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/michael-figurnov-circle.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Michael Figurnov</name>
                <br/>(Михаил Фигурнов)
              </p>
              <p>I am a Senior Research Scientist at <a href="https://deepmind.com/">DeepMind</a>.
                Before joining DeepMind, I was a PhD student at the <a href="https://bayesgroup.ru/">Bayesian Methods Research Group</a> under the supervision of <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Dmitry Vetrov</a>.
              </p>
              <p>
                My research interests include deep learning, Bayesian methods, and protein folding.
                I've worked on <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">AlphaFold</a> system which has been recognized as the solution to the protein folding problem.
              </p>
              <p style="text-align:center">
                <a href="mailto:michael@figurnov.ru">Email</a> &nbsp;/&nbsp;
                <!-- <a href="data/michael-figurnov-cv.pdf">CV</a> &nbsp;/&nbsp; -->
                <a href="data/michael-figurnov-bio.txt">Bio</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=qd0tOpQAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://twitter.com/mfigurnov">Twitter</a> &nbsp;/&nbsp;
                <a href="https://github.com/mfigurnov/">Github</a>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <strong>Nov 2020</strong>: We have announced a new version of <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">AlphaFold</a> at <a href="https://predictioncenter.org/casp14/index.cgi">CASP14</a>.
            </p>
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/alphafold-protein.jpg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">
              <papertitle>High Accuracy Protein Structure Prediction Using Deep Learning</papertitle>
            </a>
            <br>
            John Jumper&#42;, Richard Evans&#42;, Alexander Pritzel&#42;, Tim Green&#42;, <strong>Michael Figurnov&#42;</strong>, Kathryn Tunyasuvunakool&#42;, Olaf Ronneberger&#42;, Russ Bates&#42;, Augustin Žídek&#42;, Alex Bridgland&#42;, Clemens Meyer&#42;, Simon A A Kohl&#42;, Anna Potapenko&#42;, Andrew J Ballard&#42;, Andrew Cowie&#42;, Bernardino Romera-Paredes&#42;, Stanislav Nikolov&#42;, Rishub Jain&#42;, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Martin Steinegger, Michalina Pacholska, David Silver, Oriol Vinyals, Andrew W Senior, Koray Kavukcuoglu, Pushmeet Kohli, Demis Hassabis
            <br>
            <em>Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book)</em>, 30 November - 4 December 2020  
            <br>
            <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">blog post</a> /
            <a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">abstract</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/mc-gradients.jpg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1906.10652">
              <papertitle>Monte Carlo Gradient Estimation in Machine Learning</papertitle>
            </a>
            <br>
            Shakir Mohamed&#42;, Mihaela Rosca&#42;, <strong>Michael Figurnov&#42;</strong>, Andriy Mnih&#42;
            <br>
            <em>JMLR</em>, 2020
            <br>
            <a href="https://arxiv.org/abs/1906.10652">arxiv</a> /
            <a href="https://github.com/deepmind/mc_gradients">code (TensorFlow)</a> /
            <a href="https://github.com/deepmind/optax/blob/653e62ed842f69c7237fd18818518e6cad3dfdbb/optax/_src/stochastic_gradient_estimators.py">code (JAX)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/t3f.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1801.01928">
              <papertitle>Tensor Train Decomposition on TensorFlow (T3F)</papertitle>
            </a>
            <br>
            Alexander Novikov, Pavel Izmailov, Valentin Khrulkov, <strong>Michael Figurnov</strong>, Ivan V Oseledets
            <br>
            <em>JMLR Open Source Software</em>, 2020
            <br>
            <a href="https://arxiv.org/abs/1801.01928">arxiv</a> /
            <a href="https://github.com/Bihaqo/t3f">code (TensorFlow)</a> /
            <a href="https://pypi.org/project/t3f/">Python package</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/measure-valued.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="http://bayesiandeeplearning.org/2019/papers/76.pdf">
              <papertitle>Measure-Valued Derivatives for Approximate Bayesian Inference</papertitle>
            </a>
            <br>
            Mihaela Rosca&#42;, <strong>Michael Figurnov&#42;</strong>, Shakir Mohamed, Andriy Mnih
            <br>
            <em>Bayesian Deep Learning (NeurIPS Workshop)</em> <strong>oral</strong>, 2019
            <br>
            <a href="http://bayesiandeeplearning.org/2019/papers/76.pdf">paper</a> /
            <a href="https://slideslive.com/38922668/contributed-talk-measure-valued-derivatives-for-approximate-bayesian-inference?locale=en">talk (11 minutes)</a> /
            <a href="https://github.com/deepmind/mc_gradients">code (TensorFlow)</a> /
            <a href="https://github.com/deepmind/optax/blob/653e62ed842f69c7237fd18818518e6cad3dfdbb/optax/_src/stochastic_gradient_estimators.py">code (JAX)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/vaeac.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1806.02382">
              <papertitle>Variational Autoencoder with Arbitrary Conditioning</papertitle>
            </a>
            <br>
            Oleg Ivanov, <strong>Michael Figurnov</strong>, Dmitry Vetrov
            <br>
            <em>ICLR</em>, 2019
            <br>
            <a href="https://arxiv.org/abs/1806.02382">arxiv</a> /
            <a href="https://postersession.ai/poster/variational-autoencoder-with-arbitrary-c/">poster</a> /
            <a href="https://github.com/tigvarts/vaeac">code</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/implicit-reparameterization-gradients.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1805.08498">
              <papertitle>Implicit reparameterization gradients</papertitle>
            </a>
            <br>
            <strong>Michael Figurnov</strong>, Shakir Mohamed, Andriy Mnih
            <br>
            <em>NeurIPS</em> <strong>spotlight</strong>, 2018
            <br>
            <a href="https://arxiv.org/abs/1805.08498">arxiv</a> /
            <a href="https://drive.google.com/file/d/1lMLOKIxQWKgII1GrRvJwfZfaETVZQtbt/view">poster</a> /
            <a href="https://youtube.videoken.com/embed/6VT0nvWuv-4?tocitem=21">spotlight video (3 minutes)</a> /
            <a href="https://nips.cc/media/Slides/nips/2018/220e(06-09-45)-06-10-00-12714-Implicit_Repara.pdf">spotlight slides</a> /
            code is integrated into TensorFlow and TensorFlow Probability, eg:
            <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Gamma">Gamma distribution</a>,
            <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Beta">Beta distribution</a>,
            <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Dirichlet">Dirichlet distribution</a>,
            <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/VonMises">Von Mises distribution</a>,
            <a href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MixtureSameFamily">mixture of distributions (set reparameterize=True)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/pact.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://journals.pan.pl/Content/109870/PDF/06_811-820_00938_Bpast.No.66-6_31.12.18_K2.pdf">
              <papertitle>Probabilistic Adaptive Computation Time</papertitle>
            </a>
            <br>
            <strong>Michael Figurnov</strong>, Artem Sobolev, Dmitry Vetrov
            <br>
            <em>Bulletin of the Polish Academy of Sciences; Deep Learning: Theory and Practice</em>, 2018
            <br>
            <a href="https://journals.pan.pl/Content/109870/PDF/06_811-820_00938_Bpast.No.66-6_31.12.18_K2.pdf">paper</a> /
            <a href="https://arxiv.org/abs/1712.00386">arxiv (slightly older version)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/sact-ponder-cost.jpg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1612.02297">
              <papertitle>Spatially Adaptive Computation Time for Residual Networks</papertitle>
            </a>
            <br>
            <strong>Michael Figurnov</strong>, Maxwell D. Collins, Yukun Zhu, Li Zhang, Jonathan Huang, Dmitry Vetrov, Ruslan Salakhutdinov
            <br>
            <em>CVPR</em>, 2017
            <br>
            <a href="https://arxiv.org/abs/1612.02297">arxiv</a> /
            <a href="https://drive.google.com/file/d/1zwz2q8fV6g36a4WmJM-i4kgBHDgw9AXd/view">poster</a> /
            <a href="https://github.com/mfigurnov/sact">code (TensorFlow)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/perforatedcnns.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1504.08362">
              <papertitle>PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions</papertitle>
            </a>
            <br>
            <strong>Michael Figurnov</strong>, Aijan Ibraimova, Dmitry Vetrov, Pushmeet Kohli
            <br>
            <em>NeurIPS</em>, 2016
            <br>
            <a href="https://arxiv.org/abs/1504.08362">arxiv</a> /
            <a href="https://drive.google.com/file/d/1qn_UB5o6gvL50OKNVqPNhJzmMYYS5XUG/view">poster</a> /
            <a href="https://github.com/mfigurnov/perforated-cnn-caffe">code (Caffe)</a> /
            <a href="https://github.com/mfigurnov/perforated-cnn-matconvnet">code (MatConvNet)</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/robust-vi.png' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1611.09226">
              <papertitle>Robust Variational Inference</papertitle>
            </a>
            <br>
            <strong>Michael Figurnov</strong>, Kirill Struminsky, Dmitry Vetrov
            <br>
            <em>Advances in Approximate Bayesian Inference, NeurIPS</em>, 2016
            <br>
            <a href="https://arxiv.org/abs/1611.09226">arxiv</a>
            <p></p>
          </td>
        </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Talks</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/deepbayes-2018.jpg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://drive.google.com/file/d/1GYuwd_3_RF1uCNQ2idNc_WfGMuttIndA/view">
              <papertitle>Extending the Reparameterization Trick</papertitle>
            </a>
            <br>
            <em><a href="http://deepbayes.ru/2018/">DeepBayes Summer School</a></em>, 2018
            <br>
            <a href="https://drive.google.com/file/d/1GYuwd_3_RF1uCNQ2idNc_WfGMuttIndA/view">slides</a> /
            <a href="https://youtu.be/BV465lgleHA">video</a>
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images/deepbayes-2017.jpg' width="160">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://docs.google.com/presentation/d/1TOsUjgrdTlZFYVn3M88GdRQy9aKdce4VYIRqcfXDClk">
              <papertitle>Attention Models for Deep Learning</papertitle>
            </a>
            <br>
            <em><a href="http://deepbayes.ru/2017/">DeepBayes Summer School</a></em>, 2017
            <br>
            <a href="https://docs.google.com/presentation/d/1TOsUjgrdTlZFYVn3M88GdRQy9aKdce4VYIRqcfXDClk">slides</a> /
            <a href="https://youtu.be/_XRBlhzb31U">video (in Russian)</a>
            <p></p>
          </td>
        </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thanks to <a href="http://jonbarron.info/">Jon Barron</a> for the template!
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
